{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd \n",
    "import time \n",
    "from PIL import Image\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from cv2.xfeatures2d import FREAK_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract feature descriptors from each image in files_dir\n",
    "def extract_orb(files_dir, category):\n",
    "    #print(\"files dir: \", files_dir)\n",
    "    start_func = time.time()\n",
    "    category_dir = \"/\".join((files_dir, category))\n",
    "    #print(\"category dir: \", category_dir)\n",
    "    val_img = os.listdir(category_dir)\n",
    "    # filename = folder + '_' + cat + '_ORB.json'\n",
    "    # path = folder + '/' + cat\n",
    "    descriptors = []\n",
    "    orb = cv.ORB_create()\n",
    "    freak = FREAK_create()\n",
    "\n",
    "    #following code computes descriptors for FREAK.\n",
    "    #code computing ORB descriptors would use descriptors from ORB.detectAndCompute\n",
    "    for img_name in val_img:\n",
    "        img_dir = \"/\".join((category_dir, img_name))\n",
    "        #image = cv.imread(file_path)\n",
    "        #print(img_dir)\n",
    "        img = np.array(Image.open(img_dir).convert('LA'))\n",
    "        imageKeys, imageDesc = orb.detectAndCompute(img[:,:,0], None)\n",
    "\n",
    "        imageKeys, imageDesc = freak.compute(img[:,:,0], imageKeys)\n",
    "\n",
    "        if not imageDesc is None:\n",
    "            #imageDesc = [desc.tolist() for desc in imageDesc]\n",
    "            descriptors.append(imageDesc)\n",
    "    print(\"Time Taken: {:.2f}s\".format(time.time() - start_func))\n",
    "    return(descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = os.getcwd()\n",
    "val_car_dir = 'contains_car'\n",
    "val_nocar_dir = 'no_car'"
   ]
  },
  {
   "source": [
    "#extract feature descriptors for each catagory of augmented images, then save them as a file\n",
    "car_val_bright = extract_orb(files_dir = val_car_dir, category = 'bright')\n",
    "nocar_val_bright = extract_orb(files_dir = val_nocar_dir, category = 'bright')\n",
    "# with open(\"car_val_bright.txt\", 'wb') as output:\n",
    "#     pickle.dump(car, output)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Taken: 28.96s\n",
      "Time Taken: 47.31s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"car_val_bright.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_bright, output)\n",
    "with open(\"nocar_val_bright.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_bright, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Taken: 36.08s\n",
      "Time Taken: 64.37s\n"
     ]
    }
   ],
   "source": [
    "car_val_flip = extract_orb(files_dir = val_car_dir, category = 'flipped')\n",
    "nocar_val_flip = extract_orb(files_dir = val_nocar_dir, category = 'flipped')\n",
    "\n",
    "with open(\"car_val_flip.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_flip, output)\n",
    "with open(\"nocar_val_flip.txt\", 'wb') as output:\n",
    "    pickle.dump(nocar_val_flip, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Taken: 36.79s\n",
      "Time Taken: 52.42s\n"
     ]
    }
   ],
   "source": [
    "car_val_rotate = extract_orb(files_dir = val_car_dir, category = 'rotated')\n",
    "nocar_val_rotate = extract_orb(files_dir = val_nocar_dir, category = 'rotated')\n",
    "\n",
    "with open(\"car_val_rotated.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_rotate, output)\n",
    "with open(\"nocar_val_rotated.txt\", 'wb') as output:\n",
    "    pickle.dump(nocar_val_rotate, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Taken: 33.02s\n",
      "Time Taken: 53.83s\n"
     ]
    }
   ],
   "source": [
    "car_val_zoom = extract_orb(files_dir = val_car_dir, category = 'zoom')\n",
    "nocar_val_zoom = extract_orb(files_dir = val_nocar_dir, category = 'zoom')\n",
    "\n",
    "with open(\"car_val_zoom.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_zoom, output)\n",
    "with open(\"nocar_val_zoom.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_zoom, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts features for every mixed augmented image in files_dir\n",
    "def extract_mixed_orb(files_dir):\n",
    "    #print(\"files dir: \", files_dir)\n",
    "    start_func = time.time()\n",
    "    #print(\"category dir: \", category_dir)\n",
    "    val_img = os.listdir(files_dir)\n",
    "    # filename = folder + '_' + cat + '_ORB.json'\n",
    "    # path = folder + '/' + cat\n",
    "    descriptors = []\n",
    "    orb = cv.ORB_create()\n",
    "    freak = FREAK_create()\n",
    "\n",
    "    for img_name in val_img:\n",
    "        img_dir = \"/\".join((files_dir, img_name))\n",
    "        #image = cv.imread(file_path)\n",
    "        #print(img_dir)\n",
    "        img = np.array(Image.open(img_dir).convert('LA'))\n",
    "        imageKeys, imageDesc = orb.detectAndCompute(img[:,:,0], None)\n",
    "\n",
    "        imageKeys, imageDesc = freak.compute(img[:,:,0], imageKeys)\n",
    "\n",
    "        if not imageDesc is None:\n",
    "            #imageDesc = [desc.tolist() for desc in imageDesc]\n",
    "            descriptors.append(imageDesc)\n",
    "    print(\"Time Taken: {:.2f}s\".format(time.time() - start_func))\n",
    "    return(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Taken: 30.50s\n",
      "Time Taken: 45.17s\n"
     ]
    }
   ],
   "source": [
    "#extract mixed augmentation features, then save them.\n",
    "val_car_dir = \"./val_cars\"\n",
    "val_nocar_dir = \"./val_nocars\"\n",
    "car_val_mixed = extract_mixed_orb(files_dir = val_car_dir)\n",
    "nocar_val_mixed = extract_mixed_orb(files_dir = val_nocar_dir)\n",
    "\n",
    "with open(\"car_val_mixed.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_mixed, output)\n",
    "with open(\"nocar_val_mixed.txt\", 'wb') as output:\n",
    "    pickle.dump(car_val_mixed, output)"
   ]
  }
 ]
}